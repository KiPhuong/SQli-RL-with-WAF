import os
import torch
import torch.nn as nn
import torch.optim as optim
import numpy as np
import random
from collections import deque
from typing import List, Tuple, Dict, Any
from env import SQLiEnvironment
from gen_action import ActionSpace
import re

class DQN(nn.Module):
    """Deep Q-Network for token selection"""
    def __init__(self, state_size: int, action_size: int, hidden_sizes: List[int] = [512, 256, 128]):
        super(DQN, self).__init__()
        layers = []
        input_size = state_size
        for hidden_size in hidden_sizes:
            layers.append(nn.Linear(input_size, hidden_size))
            layers.append(nn.ReLU())
            layers.append(nn.Dropout(0.2))
            input_size = hidden_size
        layers.append(nn.Linear(input_size, action_size))
        self.network = nn.Sequential(*layers)
        self.apply(self._init_weights)

    def _init_weights(self, module):
        if isinstance(module, nn.Linear):
            torch.nn.init.xavier_uniform_(module.weight)
            module.bias.data.fill_(0.01)

    def forward(self, x):
        return self.network(x)


class BoltzmannExploration:
    """Boltzmann (Softmax) exploration strategy"""
    def __init__(self, initial_temperature: float = 2.0, min_temperature: float = 0.1, decay_rate: float = 0.99):
        self.initial_temperature = initial_temperature
        self.temperature = initial_temperature
        self.min_temperature = min_temperature
        self.decay_rate = decay_rate

    def select_action(self, q_values: np.ndarray) -> int:
        scaled_q_values = q_values / max(self.temperature, self.min_temperature)
        exp_values = np.exp(scaled_q_values - np.max(scaled_q_values))
        probabilities = exp_values / np.sum(exp_values)
        return np.random.choice(len(q_values), p=probabilities)

    def update_temperature(self):
        self.temperature = max(self.min_temperature, self.temperature * self.decay_rate)

    def reset_temperature(self):
        self.temperature = self.initial_temperature


class SQLiRLAgent:
    """RL Agent for SQL Injection Token Selection with Transition Masking"""

    def __init__(self, state_size: int, action_size: int, config: Dict[str, Any] = None):
        self.state_size = state_size
        self.action_size = action_size

        # Default configuration
        default_config = {
            'learning_rate': 0.001,
            'gamma': 0.99,
            'memory_size': 10000,
            'batch_size': 32,
            'target_update_freq': 100,
            'hidden_sizes': self._calculate_hidden_sizes(state_size, action_size),
            'initial_temperature': 2.0,
            'min_temperature': 0.1,
            'temperature_decay': 0.9999
        }
        self.config = {**default_config, **(config or {})}

        print(f"üß† Neural Network Architecture:")
        print(f"   Input: {state_size} ‚Üí Hidden: {self.config['hidden_sizes']} ‚Üí Output: {action_size}")

        # Token handling
        #self.start_tokens = ['SPACE', 'UNION'] # C√≥ th·ªÉ ƒëi·ªÅu ch·ªânh
        self.start_tokens = ['SPACE']
        self.token_list = self._get_token_list()
        self.token_to_id = {token: idx for idx, token in enumerate(self.token_list)}
        self.id_to_token = {idx: token for idx, token in enumerate(self.token_list)}
        self.start_token_ids = [self.token_to_id[token] for token in self.start_tokens if token in self.token_to_id]
        self.transition_table = self._build_transition_table("sqli-misc.txt")
        self.transition_table_noSpace = self._build_transition_table_no_space("sqli-misc.txt")

        # Precompute unions to be used as reasonable fallbacks (gi·ªØ gi·ªõi h·∫°n trong corpus thay v√¨ 'm·ªçi token')
        self.union_next_no_space = self._compute_union(self.transition_table_noSpace)
        self.union_next_all = self._compute_union(self.transition_table)
        
        # print(f"[DEBUG in agent] Transition table: ")
        # self.print_transition_table(self.transition_table)
        # print(f"[DEBUG in agent] Transition table noSpace: ")
        # self.print_transition_table(self.transition_table_noSpace)

        # Networks
        self.q_network = DQN(state_size, action_size, self.config['hidden_sizes'])
        self.target_network = DQN(state_size, action_size, self.config['hidden_sizes'])
        self.optimizer = optim.Adam(self.q_network.parameters(), lr=self.config['learning_rate'])

        # Exploration strategy
        self.exploration = BoltzmannExploration(
            self.config['initial_temperature'],
            self.config['min_temperature'],
            self.config['temperature_decay']
        )

        # Experience replay
        self.memory = deque(maxlen=self.config['memory_size'])
        self.step_count = 0
        self.update_target_network()


    def _calculate_hidden_sizes(self, state_size: int, action_size: int) -> List[int]:
        if action_size <= 100:
            return [512, 256, 128]
        elif action_size <= 500:
            return [1024, 512, 256]
        else:
            return [2048, 1024, 512]

    def _get_token_list(self):
        # T√πy v√†o project: c√≥ th·ªÉ load t·ª´ file ho·∫∑c ƒë·ªãnh nghƒ©a s·∫µn
        # return [str(i) for i in range(self.action_size)]
        action_space = ActionSpace("keywords.txt")
        return action_space.tokens

    def _build_transition_table(self, filename):
        """
        X√¢y d·ª±ng b·∫£ng chuy·ªÉn ti·∫øp token t·ª´ file sqli_misc.txt, gi·ªØ c·∫£ d·∫•u c√°ch l√† token,
        lo·∫°i b·ªè tr√πng l·∫∑p.
        """
        table = {}
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                #tokens = re.findall(r"\s+|,|[^\s,]+,--|#|'.*?'|\w+|\d+|[(),]", line.rstrip('\n'))
                #tokens = ['SPACE' if t == ' ' else t.upper() for t in tokens]
                tokens = [("SPACE" if re.fullmatch(r"\s+", t) else t.upper())
                    for t in re.findall(
                    r"--.*?$|#.*?$|'|\"|\s+|\d+|[A-Za-z_][A-Za-z0-9_]*|[(),]|[^'\sA-Za-z0-9_(),]", line,flags=re.MULTILINE)
                ]
                for i in range(len(tokens) - 1):
                    prev_token = tokens[i]
                    next_token = tokens[i + 1]
                    if prev_token not in table:
                        table[prev_token] = []
                    if next_token not in table[prev_token]:
                        table[prev_token].append(next_token)
        return table
    def _build_transition_table_no_space(self, filename):
        """
        X√¢y d·ª±ng b·∫£ng chuy·ªÉn ti·∫øp token t·ª´ file, B·ªé QUA token l√† SPACE.
        """
        table = {}
        with open(filename, 'r', encoding='utf-8') as f:
            for line in f:
                #tokens = re.findall(r"\s+|,|[^\s,]+,--|#|'.*?'|\w+|\d+|[(),]", line.rstrip('\n'))
                tokens = [("SPACE" if re.fullmatch(r"\s+", t) else t.upper())
                    for t in re.findall(
                    r"--.*?$|#.*?$|'|\"|\s+|\d+|[A-Za-z_][A-Za-z0-9_]*|[(),]|[^'\sA-Za-z0-9_(),]", line,flags=re.MULTILINE)
                ]
                # B·ªè qua token l√† d·∫•u c√°ch
                #tokens = [t.upper() for t in tokens if t != ' ']
                tokens = [t for t in tokens if t != "SPACE"]
                for i in range(len(tokens) - 1):
                    prev_token = tokens[i]
                    next_token = tokens[i + 1]
                    if prev_token not in table:
                        table[prev_token] = []
                    if next_token not in table[prev_token]:
                        table[prev_token].append(next_token)
        return table
        

    def print_transition_table(self, table):
        print(f"{'Prev Token':<25} {'Next Token':<15}")
        print("-" * 40)
        for prev_token, next_tokens in table.items():
            for next_token in next_tokens:
                print(f"{prev_token:<25} {next_token:<15}")

    # def select_token(self, state: np.ndarray, step_idx: int = 0, prev_token: str = None) -> int:
    #     self.q_network.eval()
    #     with torch.no_grad():
    #         state_tensor = torch.FloatTensor(state).unsqueeze(0)
    #         q_values = self.q_network(state_tensor).cpu().numpy()[0]

    #     mask = np.zeros_like(q_values)

    #     if step_idx == 0:
    #         for idx in self.start_token_ids:
    #             mask[idx] = 1
    #     elif prev_token and prev_token in self.transition_table:
    #         for token in self.transition_table[prev_token]:
    #             idx = self.token_to_id.get(token)
    #             if idx is not None:
    #                 mask[idx] = 1
    #     else:
    #         mask[:] = 1  # kh√¥ng match mapping ‚Üí cho t·∫•t c·∫£ h·ª£p l·ªá

    #     # N·∫øu kh√¥ng c√≥ action n√†o h·ª£p l·ªá, fallback cho ph√©p t·∫•t c·∫£
    #     if np.sum(mask) == 0:
    #         mask[:] = 1

    #     masked_q = np.where(mask, q_values, -np.inf)
    #     exp_q = np.exp(masked_q - np.max(masked_q))
    #     probs = exp_q / np.sum(exp_q)
    #     action = np.random.choice(len(q_values), p=probs)

    #     return action

    def select_token(self, state: np.ndarray, step_idx: int = 0, prev_token: str = None, prev_prev_token: str = None) -> int:
        self.q_network.eval()
        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0)
            q_values = self.q_network(state_tensor).cpu().numpy()[0]

        mask = np.zeros_like(q_values)

        if step_idx == 0:
            for idx in self.start_token_ids:
                mask[idx] = 1
        elif prev_token == "SPACE" and prev_prev_token in self.transition_table_noSpace:
            # N·∫øu prev_token l√† SPACE, d√πng transition_table_noSpace
            for token in self.transition_table_noSpace[prev_prev_token]:
                idx = self.token_to_id.get(token)
                if idx is not None:
                    mask[idx] = 1
        elif prev_token and prev_token in self.transition_table:
            for token in self.transition_table[prev_token]:
                idx = self.token_to_id.get(token)
                if idx is not None:
                    mask[idx] = 1
        else:
            mask[:] = 1  # kh√¥ng match mapping ‚Üí cho t·∫•t c·∫£ h·ª£p l·ªá

        if np.sum(mask) == 0:
            mask[:] = 1

        # masked_q = np.where(mask, q_values, -np.inf)
        # exp_q = np.exp(masked_q - np.max(masked_q))
        # probs = exp_q / np.sum(exp_q)

        masked_q = np.full_like(q_values, -np.inf)
        masked_q[mask.astype(bool)] = q_values[mask.astype(bool)]

        # tr√°nh nan
        if np.all(~np.isfinite(masked_q)):
            masked_q = q_values  # fallback: cho ph√©p t·∫•t c·∫£

        logits = (masked_q - np.nanmax(masked_q)) / max(self.exploration.temperature, 1e-6)
        exp_q = np.exp(logits)
        probs = exp_q / np.sum(exp_q)

        action = np.random.choice(len(q_values), p=probs)
        # print(f"[DEBUG in agent] Q-values: \n {q_values}")
        # print(f"[DEBUG in agent] Probs Action: \n {probs}")
        # print(f"[DEBUG in agent] Prev_prev_token: {str(prev_prev_token):<10} || Prve_token: {str(prev_token):<10} || Action selected: {self.id_to_token.get(action)}")
        return action

        # --- helper: compute union of next tokens from a transition table ---
    def _compute_union(self, table: Dict[str, List[str]]) -> set:
        s = set()
        for lst in table.values():
            s.update(lst)
        return s

    def _tokens_to_ids(self, tokens_set: set) -> set:
        ids = set()
        for tok in tokens_set:
            idx = self.token_to_id.get(tok)
            if idx is not None:
                ids.add(idx)
        return ids

    def _get_allowed_ids(self, step_idx: int, prev_token: str = None, prev_prev_token: str = None) -> set:
        """
        Tr·∫£ v·ªÅ set c√°c action ids h·ª£p l·ªá d·ª±a tr√™n step_idx, prev_token, prev_prev_token.
        Quy t·∫Øc:
         - step_idx == 0: tr·∫£ v·ªÅ start_token_ids (n·∫øu r·ªóng -> fallback c·∫•p ph√©p t·∫•t c·∫£ nh∆∞ng warn)
         - n·∫øu prev_token == 'SPACE': n·∫øu c√≥ prev_prev_token -> xem transition_table_noSpace[prev_prev_token]
                                       ng∆∞·ª£c l·∫°i -> union_next_no_space (fallback, h·∫°n ch·∫ø trong corpus)
         - n·∫øu prev_token in transition_table -> d√πng transition_table[prev_token]
         - else -> fallback union_next_all (t·∫≠p token xu·∫•t hi·ªán trong corpus)
        """
        # Begin
        if step_idx == 0:
            allowed_ids = set(self.start_token_ids)
            if len(allowed_ids) == 0:
                # c·ª±c hi·∫øm ‚Äî cho ph√©p t·∫•t c·∫£ nh∆∞ng b√°o
                print("[WARN] start_token_ids empty ‚Äî allowing all tokens as fallback")
                return set(range(self.action_size))
            return allowed_ids

        # case prev_token is SPACE (we want next token that follows the token before SPACE)
        if prev_token == "SPACE":
            if prev_prev_token is not None and prev_prev_token in self.transition_table_noSpace:
                allowed_tokens = set(self.transition_table_noSpace[prev_prev_token])
            else:
                # fallback: union of tokens that ever follow non-space tokens (h·∫°n ch·∫ø trong corpus)
                allowed_tokens = set(self.union_next_no_space)
        elif prev_token is not None and prev_token in self.transition_table:
            allowed_tokens = set(self.transition_table[prev_token])
        else:
            # fallback: union of all next tokens observed in corpus
            allowed_tokens = set(self.union_next_all)
            # additionally include start tokens (optional)
            allowed_tokens.update([self.id_to_token[i] for i in self.start_token_ids if i in self.id_to_token])

        allowed_ids = self._tokens_to_ids(allowed_tokens)
        if not allowed_ids:
            # n·∫øu v·∫´n kh√¥ng c√≥ token h·ª£p l·ªá, fallback an to√†n: cho ph√©p t·∫•t c·∫£
            print("[WARN] Allowed token ids empty -> fallback to ALL actions")
            allowed_ids = set(range(self.action_size))
        return allowed_ids

    def _masked_softmax(self, q_values: np.ndarray, mask_bool: np.ndarray) -> np.ndarray:
        """
        Softmax c√≥ mask, d√πng temperature self.exploration.temperature v√† fallback n·∫øu c·∫ßn.
        - q_values: shape (action_size,)
        - mask_bool: boolean np array shape (action_size,) True=allowed
        """
        # M·∫£ng logits: -inf ·ªü ch·ªó kh√¥ng ƒë∆∞·ª£c ph√©p
        masked_q = np.full_like(q_values, -np.inf, dtype=float)
        if mask_bool.any():
            masked_q[mask_bool] = q_values[mask_bool]
        else:
            # fallback: allow all (rare)
            masked_q = q_values.copy()

        # ki·ªÉm tra ph·∫ßn t·ª≠ h·ªØu h·∫°n
        finite_mask = np.isfinite(masked_q)
        if not finite_mask.any():
            # kh√¥ng c√≥ gi√° tr·ªã h·ªØu h·∫°n ‚Üí fallback uniform tr√™n mask (n·∫øu mask bool any) ho·∫∑c uniform global
            if mask_bool.any():
                probs = mask_bool.astype(float) / float(mask_bool.sum())
            else:
                probs = np.ones_like(q_values, dtype=float) / float(len(q_values))
            return probs

        # numeric stability: l·∫•y max tr√™n c√°c gi√° tr·ªã h·ªØu h·∫°n
        max_val = float(np.max(masked_q[finite_mask]))
        T = max(self.exploration.temperature, 1e-6)
        scaled = (masked_q - max_val) / T

        exp_vals = np.zeros_like(scaled, dtype=float)
        exp_vals[finite_mask] = np.exp(scaled[finite_mask])

        sum_exp = float(np.sum(exp_vals))
        if not np.isfinite(sum_exp) or sum_exp <= 0:
            # fallback: uniform over mask_bool
            if mask_bool.any():
                probs = mask_bool.astype(float) / float(mask_bool.sum())
            else:
                probs = np.ones_like(q_values, dtype=float) / float(len(q_values))
            return probs

        probs = exp_vals / sum_exp
        return probs


    def get_q_values(self, state: np.ndarray) -> np.ndarray:
        self.q_network.eval()
        with torch.no_grad():
            state_tensor = torch.FloatTensor(state).unsqueeze(0)
            return self.q_network(state_tensor).cpu().numpy()[0]

    def remember(self, state: np.ndarray, action: int, reward: float, next_state: np.ndarray, done: bool):
        self.memory.append((state, action, reward, next_state, done))

    def replay(self):
        if len(self.memory) < self.config['batch_size']:
            return
        batch = random.sample(self.memory, self.config['batch_size'])
        states, actions, rewards, next_states, dones = zip(*batch)

        states = torch.FloatTensor(np.array(states))
        actions = torch.LongTensor(actions)
        rewards = torch.FloatTensor(rewards)
        next_states = torch.FloatTensor(np.array(next_states))
        dones = torch.BoolTensor(dones)

        current_q_values = self.q_network(states).gather(1, actions.unsqueeze(1))
        next_q_values = self.target_network(next_states).max(1)[0].detach()
        target_q_values = rewards + (self.config['gamma'] * next_q_values * ~dones)

        loss = nn.MSELoss()(current_q_values.squeeze(), target_q_values)
        self.optimizer.zero_grad()
        loss.backward()
        torch.nn.utils.clip_grad_norm_(self.q_network.parameters(), 1.0)
        self.optimizer.step()

        self.step_count += 1
        if self.step_count % self.config['target_update_freq'] == 0:
            self.update_target_network()

    def update_target_network(self):
        self.target_network.load_state_dict(self.q_network.state_dict())

    def decay_temperature(self):
        self.exploration.update_temperature()

    def save_model(self, filepath: str):
        torch.save({
            'q_network_state_dict': self.q_network.state_dict(),
            'target_network_state_dict': self.target_network.state_dict(),
            'optimizer_state_dict': self.optimizer.state_dict(),
            'config': self.config,
            'step_count': self.step_count
        }, filepath)

    def load_model(self, filepath: str):
        checkpoint = torch.load(filepath)
        self.q_network.load_state_dict(checkpoint['q_network_state_dict'])
        self.target_network.load_state_dict(checkpoint['target_network_state_dict'])
        self.optimizer.load_state_dict(checkpoint['optimizer_state_dict'])
        self.step_count = checkpoint['step_count']

    def get_exploration_info(self) -> Dict[str, float]:
        return {
            'temperature': self.exploration.temperature,
            'min_temperature': self.exploration.min_temperature,
            'decay_rate': self.exploration.decay_rate
        }
